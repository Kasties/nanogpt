{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41114f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ed1e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5ec8eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c0df1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1115394,) int32\n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59  1 39 56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39\n",
      " 58 46 43 56  1 58 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47\n",
      " 57 46 12  0  0 13 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53\n",
      " 50 60 43 42  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47\n",
      " 56 57 58  6  1 63 53 59  1 49 52 53 61  1 15 39 47 59 57  1 25 39 56 41\n",
      " 47 59 57  1 47 57  1 41 46 47 43 44  1 43 52 43 51 63  1 58 53  1 58 46\n",
      " 43  1 54 43 53 54 50 43  8  0  0 13 50 50 10  0 35 43  1 49 52 53 61  5\n",
      " 58  6  1 61 43  1 49 52 53 61  5 58  8  0  0 18 47 56 57 58  1 15 47 58\n",
      " 47 64 43 52 10  0 24 43 58  1 59 57  1 49 47 50 50  1 46 47 51  6  1 39\n",
      " 52 42  1 61 43  5 50 50  1 46 39 60 43  1 41 53 56 52  1 39 58  1 53 59\n",
      " 56  1 53 61 52  1 54 56 47 41 43  8  0 21 57  5 58  1 39  1 60 43 56 42\n",
      " 47 41 58 12  0  0 13 50 50 10  0 26 53  1 51 53 56 43  1 58 39 50 49 47\n",
      " 52 45  1 53 52  5 58 11  1 50 43 58  1 47 58  1 40 43  1 42 53 52 43 10\n",
      "  1 39 61 39 63  6  1 39 61 39 63  2  0  0 31 43 41 53 52 42  1 15 47 58\n",
      " 47 64 43 52 10  0 27 52 43  1 61 53 56 42  6  1 45 53 53 42  1 41 47 58\n",
      " 47 64 43 52 57  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 35\n",
      " 43  1 39 56 43  1 39 41 41 53 59 52 58 43 42  1 54 53 53 56  1 41 47 58\n",
      " 47 64 43 52 57  6  1 58 46 43  1 54 39 58 56 47 41 47 39 52 57  1 45 53\n",
      " 53 42  8  0 35 46 39 58  1 39 59 58 46 53 56 47 58 63  1 57 59 56 44 43\n",
      " 47 58 57  1 53 52  1 61 53 59 50 42  1 56 43 50 47 43 60 43  1 59 57 10\n",
      "  1 47 44  1 58 46 43 63  0 61 53 59 50 42  1 63 47 43 50 42  1 59 57  1\n",
      " 40 59 58  1 58 46 43  1 57 59 54 43 56 44 50 59 47 58 63  6  1 61 46 47\n",
      " 50 43  1 47 58  1 61 43 56 43  0 61 46 53 50 43 57 53 51 43  6  1 61 43\n",
      "  1 51 47 45 46 58  1 45 59 43 57 57  1 58 46 43 63  1 56 43 50 47 43 60\n",
      " 43 42  1 59 57  1 46 59 51 39 52 43 50 63 11  0 40 59 58  1 58 46 43 63\n",
      "  1 58 46 47 52 49  1 61 43  1 39 56 43  1 58 53 53  1 42 43 39 56 10  1\n",
      " 58 46 43  1 50 43 39 52 52 43 57 57  1 58 46 39 58  0 39 44 44 50 47 41\n",
      " 58 57  1 59 57  6  1 58 46 43  1 53 40 48 43 41 58  1 53 44  1 53 59 56\n",
      "  1 51 47 57 43 56 63  6  1 47 57  1 39 57  1 39 52  0 47 52 60 43 52 58\n",
      " 53 56 63  1 58 53  1 54 39 56 58 47 41 59 50 39 56 47 57 43  1 58 46 43\n",
      " 47 56  1 39 40 59 52 42 39 52 41 43 11  1 53 59 56  0 57 59 44 44 43 56\n",
      " 39 52 41 43  1 47 57  1 39  1 45 39 47 52  1 58 53  1 58 46 43 51  1 24\n",
      " 43 58  1 59 57  1 56 43 60 43 52 45 43  1 58 46 47 57  1 61 47 58 46  0\n",
      " 53 59 56  1 54 47 49 43 57  6  1 43 56 43  1 61 43  1 40 43 41 53 51 43\n",
      "  1 56 39 49 43 57 10  1 44 53 56  1 58 46 43  1 45 53 42 57  1 49 52 53\n",
      " 61  1 21  0 57 54 43 39 49  1 58 46 47 57  1 47 52  1 46 59 52 45 43 56\n",
      "  1 44 53 56  1 40 56 43 39 42  6  1 52 53 58  1 47 52  1 58 46 47 56 57\n",
      " 58  1 44 53 56  1 56 43 60 43 52 45 43  8  0  0]\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "data = jnp.array(encode(text), dtype=jnp.int32)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a9e056",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3028de1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([18, 47, 56, 57, 58,  1, 15, 47, 58], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa9e0b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is [18] the target: 47\n",
      "when input is [18 47] the target: 56\n",
      "when input is [18 47 56] the target: 57\n",
      "when input is [18 47 56 57] the target: 58\n",
      "when input is [18 47 56 57 58] the target: 1\n",
      "when input is [18 47 56 57 58  1] the target: 15\n",
      "when input is [18 47 56 57 58  1 15] the target: 47\n",
      "when input is [18 47 56 57 58  1 15 47] the target: 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25355795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "(4, 8)\n",
      "[[13 30 16  1 21 34 10  0]\n",
      " [41 53 60 43 56  1 58 53]\n",
      " [46 47 57  1 39 54 54 56]\n",
      " [ 1 52 39 63  6  1 57 53]]\n",
      "targets:\n",
      "(4, 8)\n",
      "[[30 16  1 21 34 10  0 32]\n",
      " [53 60 43 56  1 58 53  1]\n",
      " [47 57  1 39 54 54 56 43]\n",
      " [52 39 63  6  1 57 53 51]]\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split, key):\n",
    "    data_arr = train_data if split == 'train' else val_data\n",
    "    \n",
    "    # Generate random starting indices\n",
    "    ix = jax.random.randint(key, (batch_size,), 0, len(data_arr) - block_size - 1)\n",
    "    \n",
    "    # Function to grab one slice, given one start index\n",
    "    def get_slice(start_i):\n",
    "        x = jax.lax.dynamic_slice(data_arr, (start_i,), (block_size,))\n",
    "        y = jax.lax.dynamic_slice(data_arr, (start_i + 1,), (block_size,))\n",
    "        return x, y\n",
    "        \n",
    "    # Vectorize this over the batch of indices\n",
    "    x, y = jax.vmap(get_slice)(ix)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "xb, yb = get_batch('train', rng)\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74687a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits shape: (32, 65)\n",
      "loss : 4.1742873\n",
      "\n",
      "3wuUShFFwYwel,e BTjJkFqurSsCQTsHKiDtNzNnHq&rJZzQLq.3EXbWOMVE$rvWJBU3dDLp;$Q;CIKkbtEJdB.JVwYYBwsWsCm,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class BigramLanguageModel:\n",
    "    def __init__(self, vocab_size, key):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.key = key\n",
    "        self.token_embedding_table = jax.random.normal(key, (vocab_size, vocab_size)) * 0.01\n",
    "\n",
    "    def __call__(self, idx,targets=None,params=None):\n",
    "        tabel = params if params is not None else self.token_embedding_table\n",
    "        logits = jnp.take(tabel, idx, axis=0)\n",
    "        if targets is None:\n",
    "            return logits, None\n",
    "        B, T, C = logits.shape\n",
    "        logits = logits.reshape(B*T, C)\n",
    "        targets = targets.reshape(B*T)\n",
    "\n",
    "        \n",
    "        loss = optax.softmax_cross_entropy_with_integer_labels(logits,targets).mean()\n",
    "\n",
    "\n",
    "        return logits,loss\n",
    "    def generate(self, idx, max_new_tokens,key):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits,loss = self(idx, targets=None)\n",
    "            logits = logits[:, -1, :] # focus only on the last time step\n",
    "            key, subkey = jax.random.split(key)\n",
    "            idx_next = jax.random.categorical(subkey, logits, axis=-1) # sample from the distribution\n",
    "            idx_next = idx_next.reshape(-1, 1)\n",
    "            idx = jnp.concatenate((idx, idx_next), axis=1) # append sampled index to the running sequence\n",
    "\n",
    "        return idx\n",
    "model = BigramLanguageModel(vocab_size, rng)\n",
    "logits,loss = model(xb, yb)\n",
    "print(\"logits shape:\", logits.shape)  # (batch_size, block_size, vocab\n",
    "print(\"loss :\", loss)    # (batch_size, block_size)\n",
    "max_new_tokens = 100\n",
    "idx = jnp.zeros((1, 1), dtype=jnp.int32)\n",
    "print(decode(model.generate(idx, max_new_tokens,rng)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3c327dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optax.adamw(learning_rate=1e-3)\n",
    "batch_size = 32\n",
    "params = model.token_embedding_table\n",
    "opt_state = optimizer.init(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "762dd508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss 4.1749796867370605\n",
      "step 10, loss 4.157289505004883\n",
      "step 20, loss 4.139647006988525\n",
      "step 30, loss 4.122057914733887\n",
      "step 40, loss 4.104523181915283\n",
      "step 50, loss 4.087052345275879\n",
      "step 60, loss 4.069634437561035\n",
      "step 70, loss 4.052274227142334\n",
      "step 80, loss 4.0349860191345215\n",
      "step 90, loss 4.017772197723389\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer_state = optimizer.init(model.token_embedding_table)\n",
    "for i in range(100):\n",
    "    xb, yb = get_batch('train', rng)\n",
    "\n",
    "    def loss_fn(params, xb, yb):\n",
    "        logits, loss = model(xb, yb,params)\n",
    "        return loss\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(model.token_embedding_table, xb, yb)\n",
    "    updates, optimizer_state = optimizer.update(grads, optimizer_state,model.token_embedding_table)\n",
    "    model.token_embedding_table = optax.apply_updates(model.token_embedding_table, updates)\n",
    "    if i % 10 == 0:\n",
    "        print(f\"step {i}, loss {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17e6a9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3wuUShFFwYwel,e BTjJkFqurSsCQTsHKiDtNzNnHq&rJZzQLq.3EXbWOMVE$rvWJBU3dDLp;$Q;CIKkbtEJdB.JVwYYBwsWsCm,\n"
     ]
    }
   ],
   "source": [
    "print(decode(model.generate(idx, max_new_tokens,rng)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ba11f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, T, C = 4, 8, 2\n",
    "x = jax.random.uniform(jax.random.PRNGKey(0), (B, T, C), minval=0, maxval=1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdb5e1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow = jnp.zeros((B, T, C), dtype=jnp.float32)\n",
    "xprev = xbow[0,:1]\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1]\n",
    "        xbow = xbow.at[b, t].set(jnp.mean(xprev, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ad863d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wei = jnp.tril(jnp.ones((T, T)))\n",
    "wei = wei / wei.sum(axis=1, keepdims=True)\n",
    "xbow2 = wei @ x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0c096e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 8, 16)\n"
     ]
    }
   ],
   "source": [
    "B, T, C = 4, 8, 32\n",
    "x = jax.random.normal(jax.random.PRNGKey(0), (B, T, C))\n",
    "head_size = 16\n",
    "W_k = jax.random.normal(jax.random.PRNGKey(0), (C, head_size)) * (C ** -0.5)\n",
    "W_q = jax.random.normal(jax.random.PRNGKey(0), (C, head_size)) * (C ** -0.5)\n",
    "W_v = jax.random.normal(jax.random.PRNGKey(0), (C, head_size)) * (C ** -0.5)\n",
    "\n",
    "k = x @ W_k # (B, T, head_size)\n",
    "q = x @ W_q # (B, T, head_size)\n",
    "wei = q @ k.transpose(0,2,1) * (head_size ** -0.5) # (B, T, 16) @ (B, head_size, T) -> (B, T, T) \n",
    "wei = jnp.where(jnp.tril(jnp.ones((T, T), dtype=bool)), wei, -jnp.inf)\n",
    "wei = jax.nn.softmax(wei, axis=-1)\n",
    "v = x @ W_v\n",
    "out = wei @ v\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caae82b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwei\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not iterable"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
